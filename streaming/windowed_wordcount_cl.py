#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

"""
 Counts words in text encoded with UTF8 received from the network every second.

 Usage: recoverable_network_wordcount.py <hostname> <port> <checkpoint-directory> <output-file>
   <hostname> and <port> describe the TCP server that Spark Streaming would connect to receive
   data. <checkpoint-directory> directory to HDFS-compatible file system which checkpoint data
   <output-file> file to which the word counts will be appended

 To run this on your local machine, you need to first run a Netcat server
    `$ nc -lk 9999`

 and then run the example
    `$ bin/spark-submit examples/src/main/python/streaming/recoverable_network_wordcount.py \
        localhost 9999 ~/checkpoint/ ~/out`

 If the directory ~/checkpoint/ does not exist (e.g. running for the first time), it will create
 a new StreamingContext (will print "Creating new context" to the console). Otherwise, if
 checkpoint data exists in ~/checkpoint/, then it will create StreamingContext from
 the checkpoint data.
"""
from __future__ import print_function

import os
import sys

from pyspark import SparkContext
from pyspark.streaming import StreamingContext


#Define clear screen function
def cls():
    tmp = os.system('clear')


# Get or register a Broadcast variable
def getWordBlacklist(sparkContext):
    if ('wordBlacklist' not in globals()):
        globals()['wordBlacklist'] = sparkContext.broadcast(["Nov", "user", "timeout","INFO"])
    return globals()['wordBlacklist']


# Get or register an Accumulator
def getDroppedWordsCounter(sparkContext):
    if ('droppedWordsCounter' not in globals()):
        globals()['droppedWordsCounter'] = sparkContext.accumulator(0)
    return globals()['droppedWordsCounter']


def createContext(host, port, checkpointDirectory):
    # If you do not see this printed, that means the StreamingContext has been loaded
    # from the new checkpoint
    print("Creating new context! Working in the current path: %s !" % os.getcwd())
    sc = SparkContext(appName="PythonStreamingWindowedWC_Cluster")
    sc.setLogLevel('ERROR')
    ssc = StreamingContext(sc, 5)

    # Create a socket stream on target ip:port and count the
    # words in input stream of \n delimited text (eg. generated by 'nc')
    lines = ssc.socketTextStream(host, port)
    words = lines.flatMap(lambda line: line.split(" "))
    pairs = words.map(lambda x: (x, 1))
    wordCounts = pairs.reduceByKeyAndWindow(lambda x, y: x + y,
                                            lambda x, y: x - y,
                                            30,10)

    def echo(time, rdd):
        # Before printing, clear terminal
        cls()
        n_elem = rdd.count()

        print("-------------------------------------------")
        print("Time: %s. Processed words: %s" % (time,n_elem))
        print("-------------------------------------------")
        lst = rdd.collect()
        if n_elem > 10:
            for elem in lst[:10]:
                print("%s=> %s"%(elem[0],elem[1]))
        elif n_elem > 0:
            for elem in lst:
                print("%s=> %s"%(elem[0],elem[1]))


    wordCounts.foreachRDD(echo)
    ssc.checkpoint(checkpointDirectory)
    return ssc

if __name__ == "__main__":
    if len(sys.argv) != 4:
        print("Usage: recoverable_network_wordcount.py <hostname> <port> "
              "<checkpoint-directory> ", file=sys.stderr)
        exit(-1)
    host, port, checkpoint  = sys.argv[1:]
    ssc = StreamingContext.getOrCreate(checkpoint,
                                       lambda: createContext(host, int(port), checkpoint))
    ssc.start()
    ssc.awaitTermination()
